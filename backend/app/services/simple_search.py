"""
SerpAPIë¥¼ í™œìš©í•œ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥
"""
import logging
import httpx
from app.core.config import settings
from langchain_openai import ChatOpenAI
from langchain_community.agent_toolkits.load_tools import load_tools
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage

logger = logging.getLogger(__name__)


async def search_web(query: str) -> str:
    """
    SerpAPIë¥¼ í™œìš©í•œ ì›¹ ê²€ìƒ‰ - ì‹¤ì œ êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´
    """
    logger.info(f"ğŸ” SerpAPI ì›¹ ê²€ìƒ‰: {query}")

    # API í‚¤ ì²´í¬
    if not settings.SERPAPI_API_KEY:
        return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ì‹¤íŒ¨"

    try:
        # SerpAPI ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            "engine": "google",
            "q": query,
            "api_key": settings.SERPAPI_API_KEY,
            "num": 3,  # ìƒìœ„ 3ê°œ ê²°ê³¼
            "hl": "ko",  # í•œêµ­ì–´
            "gl": "kr",  # í•œêµ­ ì§€ì—­
        }

        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(settings.SERPAPI_BASE_URL, params=params)
            response.raise_for_status()

            data = response.json()

            # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
            search_results = _parse_serpapi_results(data, query)
            logger.info(f"âœ… SerpAPI ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)} ê²°ê³¼")

            return search_results

    except httpx.TimeoutException:
        logger.error("âŒ SerpAPI ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
        return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ì‹¤íŒ¨"
    except httpx.HTTPStatusError as e:
        logger.error(f"âŒ SerpAPI HTTP ì˜¤ë¥˜: {e.response.status_code}")
        return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ì‹¤íŒ¨"
    except Exception as e:
        logger.error(f"âŒ SerpAPI ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ì‹¤íŒ¨"


def _parse_serpapi_results(data: dict, query: str) -> str:
    """SerpAPI ì‘ë‹µ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    try:
        organic_results = data.get("organic_results", [])

        if not organic_results:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        formatted_results = [f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:\n"]

        for i, result in enumerate(organic_results[:3], 1):
            title = result.get("title", "ì œëª© ì—†ìŒ")
            snippet = result.get("snippet", "ìš”ì•½ ì—†ìŒ")
            link = result.get("link", "")

            formatted_results.append(f"{i}. {title}")
            formatted_results.append(f"   - {snippet}")
            if link:
                formatted_results.append(f"   - ë§í¬: {link}")
            formatted_results.append("")  # ë¹ˆ ì¤„

        return "\n".join(formatted_results)

    except Exception as e:
        logger.error(f"âŒ SerpAPI ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


async def search_web_with_agent(query: str) -> str:
    # langchain_openai.ChatOpenAI ì‚¬ìš©
    try:
        llm = ChatOpenAI(model=settings.ACTIVE_LLM_MODEL, temperature=0)

        tools = load_tools(["serpapi"], llm=llm)
        agent_executor = create_react_agent(
            model=llm,
            tools=tools,
        )

        result = agent_executor.invoke({"messages": [HumanMessage(content=query)]})

        final_message = result["messages"][-1]
        return final_message.content

    except Exception as e:
        logger.error(f"âŒ Agent ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return f"'{query}' Agent ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
